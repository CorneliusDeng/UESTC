{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单进程指定GPU进行计算\n",
    "\n",
    "在Pytorch框架下，单进程指定GPU进行计算核心语句：`device = torch.device(“cuda:gpu编号”)`\n",
    "例如： `device = torch.device(“cuda:1”)`\n",
    "\n",
    "GPU编号、显存大小、当前正在使用GPU的进程都可通过命令行语句 `nvidia-smi` 查看\n",
    "\n",
    "此外，还可以通过 `CUDA_VISIBLE_DEVICES` 变量指定GPU\n",
    "\n",
    "对于模型（类），使用 `.to(device)` 语句来将模型的所有参数、缓存放到指定的GPU上进行计算\n",
    "\n",
    "注：只要显存足够，多个terminal分别执行多个进程，可以指定在同一个GPU，也可以指定在不同的GPU，即可实现多进程并行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Demo, 单进程指定GPU计算\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "# 1. 检查可用的GPU数量和编号\n",
    "device_count = torch.cuda.device_count()\n",
    "print(f\"系统中有 {device_count} 块可用的GPU。\")\n",
    "if device_count > 0:\n",
    "    print(\"它们的编号是：\")\n",
    "    for i in range(device_count):\n",
    "        print(f\"GPU {i}\")\n",
    "else:\n",
    "    print(\"没有可用的GPU。\")\n",
    "\n",
    "# 2. 随机生成两个可乘矩阵，并在指定的GPU上进行乘法运算\n",
    "if device_count > 0:\n",
    "    # 让用户输入想要使用的GPU编号\n",
    "    gpu_id = int(input(\"请输入你想要使用的GPU编号(0到{}):\".format(device_count - 1)))\n",
    "    \n",
    "    # 检查输入的GPU编号是否有效\n",
    "    if gpu_id < 0 or gpu_id >= device_count:\n",
    "        print(\"输入的GPU编号无效。\")\n",
    "    else:\n",
    "        # 指定设备\n",
    "        device = torch.device(f\"cuda:{gpu_id}\")\n",
    "        \n",
    "        # 在指定的GPU上创建两个随机的可乘矩阵\n",
    "        matrix1 = torch.rand(3, 3, device=device)\n",
    "        matrix2 = torch.rand(3, 4, device=device)\n",
    "        \n",
    "        print(f\"在GPU {gpu_id} 上的随机矩阵1:\\n{matrix1}\")\n",
    "        print(f\"在GPU {gpu_id} 上的随机矩阵2:\\n{matrix2}\")\n",
    "        \n",
    "        # 执行矩阵乘法\n",
    "        result = torch.matmul(matrix1, matrix2)\n",
    "        \n",
    "        print(f\"矩阵乘法的结果:\\n{result}\")\n",
    "else:\n",
    "    print(\"由于没有可用的GPU，无法执行GPU上的矩阵乘法。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Demo, 指定进程的GPU可见范围\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=\"1\"           Only device 1 will be seen\n",
    "CUDA_VISIBLE_DEVICES=\"0,1\"         Devices 0 and 1 will be visible\n",
    "CUDA_VISIBLE_DEVICES=\"0,1\"         Same as above, quotation marks are optional\n",
    "CUDA_VISIBLE_DEVICES=\"0,2,3\"       Devices 0, 2, 3 will be visible; device 1 is masked\n",
    "CUDA_VISIBLE_DEVICES=\"\"            No GPU will be visible\n",
    "'''\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 设置环境变量，不使用GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# 指定设备为GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"当前使用的设备:\", device)\n",
    "\n",
    "# 在指定的GPU上创建两个可以做乘法的矩阵\n",
    "matrix1 = torch.rand(2, 3, device=device)\n",
    "matrix2 = torch.rand(3, 2, device=device)\n",
    "\n",
    "# 打印生成的矩阵\n",
    "print(\"Matrix 1:\")\n",
    "print(matrix1)\n",
    "print(\"Matrix 2:\")\n",
    "print(matrix2)\n",
    "\n",
    "# 进行矩阵乘法\n",
    "result = torch.matmul(matrix1, matrix2)\n",
    "\n",
    "# 打印结果\n",
    "print(\"Result of matrix multiplication:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Demo, 把模型放到GPU上做计算\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc = nn.Linear(10, 5) \n",
    "        # self.to(torch.device(\"cuda:1\")) # 定义网络时就指定设备\n",
    "\n",
    "    # 前向传播过程\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return F.relu(x) \n",
    "\n",
    "# 指定GPU设备\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "# 实例化模型\n",
    "model = SimpleNet()\n",
    "\n",
    "# 将模型移动到指定的设备\n",
    "model.to(device)\n",
    "\n",
    "# 创建一个随机数据张量，模拟输入数据\n",
    "input_data = torch.randn(5, 10) \n",
    "\n",
    "# 将输入数据也移动到指定的设备，数据与模型在同一设备上可以提高计算效率\n",
    "input_data = input_data.to(device)\n",
    "\n",
    "# 前向传播，获取模型输出\n",
    "output = model(input_data)\n",
    "\n",
    "# 打印输出结果\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单进程跨GPU做计算\n",
    "\n",
    "在深度学习和分布式计算领域，DP 通常指的是 DataParallel。DataParallel 是一种将计算任务在多个 GPU 上并行执行的方法。它在单机多卡环境中非常有用，可以在多个 GPU 上分摊工作负载，从而加快训练速度。\n",
    "\n",
    "torch.nn.DataParallel 是 PyTorch 中的一个工具，可以让模型在多个 GPU 上并行运行。它通过将输入批次拆分成多个子批次，每个子批次发送到不同的 GPU 上，并行执行前向传播和反向传播，然后将每个 GPU 上的梯度聚合到主 GPU 上进行参数更新。\n",
    "\n",
    "使用 DataParallel 的基本步骤\n",
    "- 定义模型: 创建神经网络模型\n",
    "- 包装模型: 使用 torch.nn.DataParallel 包装模型\n",
    "- 将模型和数据迁移到 GPU: 使用 .to(device) 将模型和输入数据迁移到合适的设备上\n",
    "- 训练模型: 按照常规方式训练模型\n",
    "\n",
    "单机多卡训练策略\n",
    "- 数据拆分，模型不拆分\n",
    "- 数据不拆分，模型拆分\n",
    "- 数据拆分，模型拆分\n",
    "\n",
    "DataParallel 的局限性\n",
    "- 数据并行粒度: DataParallel 进行的是数据并行操作，每个 GPU 处理一部分数据批次。由于其自动分配负载，这可能导致 GPU 利用率不均衡，尤其是在有计算负载差异的情况下\n",
    "- 单节点限制: DataParallel 主要用于单节点多 GPU，即单机多卡。如果需要跨节点并行（分布式训练，多机多卡），应该考虑使用 torch.nn.parallel.DistributedDataParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Demo, 单机多卡, 单进程跨GPU计算\n",
    "\n",
    "最简单高效的策略: 数据拆分, 模型不拆分\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 设置环境变量，指定使用的GPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "# 定义设备\n",
    "globalDevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义一个简单的CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.fc = nn.Linear(16 * 26 * 26, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "cnn = CNN().to(globalDevice)\n",
    "\n",
    "# 检查GPU数量并设置DataParallel\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "    net = nn.DataParallel(cnn)\n",
    "else:\n",
    "    print(\"Using single GPU or CPU\")\n",
    "    net = cnn\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randn(3, 28, 28), torch.tensor(1)\n",
    "\n",
    "dataset = SimpleDataset(1000)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=20)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 简单的训练过程\n",
    "for epoch in range(5):\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(globalDevice), labels.to(globalDevice) # 此处可指定GPU以实现手动分配负载\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pseudocode，策略一：数据拆分，模型不拆分\n",
    "\n",
    "在这种策略中，将数据拆分成多个批次，每个批次在一个GPU上进行处理。模型不会拆分，而是复制到每个GPU上\n",
    "'''\n",
    "\n",
    "import torch  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from torch.utils.data import DataLoader, Dataset  \n",
    "from torch.nn.parallel import DataParallel  \n",
    "\n",
    "# 假设我们有一个自定义的数据集和模型  \n",
    "class MyDataset(Dataset):  \n",
    "    # 实现__len__和__getitem__方法  \n",
    "    pass  \n",
    "class MyModel(nn.Module):  \n",
    "    # 定义模型结构  \n",
    "    pass  \n",
    "\n",
    "# 初始化数据集和模型  \n",
    "dataset = MyDataset()  \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)  \n",
    "model = MyModel()  \n",
    "\n",
    "# 检查GPU数量  \n",
    "device_ids = list(range(torch.cuda.device_count()))  \n",
    "model = DataParallel(model, device_ids=device_ids).to(device_ids[0])  \n",
    "\n",
    "# 定义损失函数和优化器  \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# 训练循环  \n",
    "for epoch in range(num_epochs):  \n",
    "    for inputs, labels in dataloader:  \n",
    "        inputs, labels = inputs.to(device_ids[0]), labels.to(device_ids[0])  \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pseudocode，策略二：数据不拆分，模型拆分\n",
    "\n",
    "在这种策略中，整个数据集在每个GPU上都会有一份副本，但模型会被拆分成多个部分，每个部分在一个GPU上运行。这种策略通常不常见，因为数据复制会消耗大量内存，而且模型拆分也可能会导致通信开销增加\n",
    "'''\n",
    "# 假设我们有一个可以拆分的模型（例如，具有多个子网络的模型）  \n",
    "class SplitModel(nn.Module):  \n",
    "    def __init__(self):  \n",
    "        super(SplitModel, self).__init__()  \n",
    "        self.subnet1 = nn.Sequential(...)  # 定义子网络1  \n",
    "        self.subnet2 = nn.Sequential(...)  # 定义子网络2  \n",
    "        # ... 其他子网络 ...  \n",
    "    def forward(self, x):  \n",
    "        # 前向传播逻辑，可能涉及跨多个设备的通信和数据传输  \n",
    "        pass  \n",
    "\n",
    "# 初始化模型和数据集（这里不实际拆分数据）  \n",
    "model = SplitModel()  \n",
    "dataset = MyDataset()  \n",
    "\n",
    "# 将模型的每个子网络分配到一个GPU上  \n",
    "model.subnet1 = model.subnet1.to('cuda:0')  \n",
    "model.subnet2 = model.subnet2.to('cuda:1')  \n",
    "\n",
    "# ... 其他子网络 ...  \n",
    "\n",
    "# 训练循环（这里省略了数据加载和批处理，因为数据没有拆分）  \n",
    "for epoch in range(num_epochs):  \n",
    "    inputs, labels = ...  # 加载数据  \n",
    "    inputs = inputs.to('cuda:0')  # 假设输入数据首先被送到第一个GPU上  \n",
    "    optimizer.zero_grad()  \n",
    "    outputs = model(inputs)  # 前向传播可能涉及跨多个GPU的通信  \n",
    "    loss = criterion(outputs, labels)  \n",
    "    loss.backward()  \n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pseudocode，策略三：数据拆分，模型拆分\n",
    "\n",
    "在这种策略中，同时使用数据并行和模型并行。数据被拆分成多个批次，每个批次在不同的GPU上进行处理，同时模型也被拆分成多个部分，每个部分在不同的GPU上运行。这通常用于非常大的模型，单个GPU无法容纳整个模型的情况\n",
    "'''\n",
    "\n",
    "import torch  \n",
    "import torch.distributed as dist  \n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "from torch.utils.data import DataLoader, Dataset, DistributedSampler  \n",
    "from torch.nn.parallel import DistributedDataParallel as DDP  \n",
    "\n",
    "# 自定义数据集和模型  \n",
    "class MyDataset(Dataset):  \n",
    "    # 实现__len__和__getitem__方法  \n",
    "    pass  \n",
    "class MyModel(nn.Module):  \n",
    "    # 定义模型结构，可能需要考虑如何拆分模型  \n",
    "    pass  \n",
    "\n",
    "# 初始化分布式环境  \n",
    "dist.init_process_group(backend='nccl', init_method='tcp://localhost:23456', rank=0, world_size=torch.cuda.device_count())  \n",
    "\n",
    "# 初始化数据集和模型  \n",
    "dataset = MyDataset()  \n",
    "sampler = DistributedSampler(dataset)  \n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, sampler=sampler)  \n",
    "model = MyModel()  \n",
    "\n",
    "#拆分模型（这通常需要根据模型的具体结构来手动完成。例如，如果模型有两个主要部分，可以将它们分别放到不同的设备上  \n",
    "model_part1 = model.part1.to('cuda:0')  \n",
    "model_part2 = model.part2.to('cuda:1')  \n",
    "\n",
    "# 使用DistributedDataParallel包装模型  \n",
    "model = DDP(model, device_ids=[torch.cuda.current_device()])\n",
    "\n",
    "# 定义损失函数和优化器  \n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "# 训练循环  \n",
    "for epoch in range(num_epochs):  \n",
    "    for inputs, labels in dataloader:  \n",
    "        inputs, labels = inputs.to(model.device), labels.to(model.device)  \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)  \n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "\n",
    "# 销毁分布式进程组  \n",
    "dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8个进程，全在单块4090显卡跑\n",
    "\n",
    "耗时49.44012928009033秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# 定义一个简单的CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.fc = nn.Linear(16 * 26 * 26, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randn(3, 28, 28), torch.tensor(1)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "def train_model(model, device, dataloader, epochs):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Process {os.getpid()} - Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    return loss.item()\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = SimpleDataset(1000)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=20)\n",
    "\n",
    "# 设置环境变量，指定使用的GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# 创建8个模型，都在gpu0\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    processes = []\n",
    "    devices = [torch.device(\"cuda:0\")] * 8\n",
    "\n",
    "    # 创建进程并开始训练\n",
    "    for i, device in enumerate(devices):\n",
    "        model = CNN()\n",
    "        p = multiprocessing.Process(target=train_model, args=(model, device, dataloader, 5))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # 等待所有进程完成\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total time for 8 models: {end_time - start_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8个进程，4090和3070各运行4个\n",
    "\n",
    "耗时42.74378538131714秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# 定义一个简单的CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.fc = nn.Linear(16 * 26 * 26, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randn(3, 28, 28), torch.tensor(1)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "def train_model(model, device, dataloader, epochs):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Process {os.getpid()} - Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    return loss.item()\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = SimpleDataset(1000)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=20)\n",
    "\n",
    "# 设置环境变量，指定使用的GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "# 创建8个模型，4个在gpu0，4个在gpu1\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    processes = []\n",
    "    devices = [torch.device(\"cuda:0\")] * 4 + [torch.device(\"cuda:1\")] * 4\n",
    "\n",
    "    # 创建进程并开始训练\n",
    "    for i, device in enumerate(devices):\n",
    "        model = CNN()\n",
    "        p = multiprocessing.Process(target=train_model, args=(model, device, dataloader, 5))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # 等待所有进程完成\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total time for 8 models: {end_time - start_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4个进程，每个进程都跨GPU运算\n",
    "\n",
    "There is an imbalance between your GPUs. You may want to exclude GPU 1 which has less than 75% of the memory or cores of GPU 0. You can do so by setting the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES environment variable.\n",
    "\n",
    "warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
    "\n",
    "耗时49.47641134262085秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# 定义一个简单的CNN模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.fc = nn.Linear(16 * 26 * 26, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 定义数据集和数据加载器\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.randn(3, 28, 28), torch.tensor(1)\n",
    "\n",
    "# 定义优化器和损失函数，并训练模型\n",
    "def train_model(dataloader, epochs):\n",
    "    # 创建模型\n",
    "    model = CNN()\n",
    "\n",
    "    # 定义设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # 检查GPU数量并设置DataParallel\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Process {os.getpid()} - Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    return loss.item()\n",
    "\n",
    "# 创建数据加载器\n",
    "dataset = SimpleDataset(1000)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=20)\n",
    "\n",
    "# 设置环境变量，指定使用的GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "# 创建4个进程，每个进程都在两个GPU上运行\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    processes = []\n",
    "\n",
    "    # 创建进程并开始训练\n",
    "    for _ in range(4):\n",
    "        p = multiprocessing.Process(target=train_model, args=(dataloader, 5))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # 等待所有进程完成\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Total time for 8 models: {end_time - start_time} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单进程处理1小时视频\n",
    "\n",
    "Total time for loading video: 162.94 seconds\n",
    "\n",
    "Total time for training model: 18.84 seconds\n",
    "\n",
    "Total time for the whole process 181.79 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loading video...\n",
      "Training model...\n",
      "Epoch 1, Loss: 2.241482734680176\n",
      "Epoch 2, Loss: 0.0029186292085796595\n",
      "Epoch 3, Loss: 0.002448895713314414\n",
      "Epoch 4, Loss: 0.0021068297792226076\n",
      "Epoch 5, Loss: 0.0018468719208613038\n",
      "Total time for loading video: 162.94 seconds\n",
      "Total time for training model: 18.84 seconds\n",
      "Total time for the whole process 181.79 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "class SimpleVideoCNN(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(SimpleVideoCNN, self).__init__()\n",
    "\n",
    "        self.conv3d_1 = nn.Conv3d(3, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.pool_1 = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "\n",
    "        self.conv3d_2 = nn.Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.pool_2 = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "\n",
    "        # 动态计算全连接层输入大小\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(input_shape)\n",
    "            output = self.pool_2(self.conv3d_2(self.pool_1(self.conv3d_1(dummy_input))))\n",
    "            self.flatten_size = output.numel() // dummy_input.size(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv3d_1(x))\n",
    "        x = self.pool_1(x)\n",
    "        x = torch.relu(self.conv3d_2(x))\n",
    "        x = self.pool_2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 读取本地视频并预处理\n",
    "def load_video(video_path, fps_to_process=None, frame_size=(64, 64)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    # 获取视频的帧率\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(original_fps // fps_to_process) if fps_to_process and fps_to_process < original_fps else 1\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:  # 没有读取到帧时退出循环\n",
    "            break\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, frame_size)  # 缩放帧大小\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # 转换为 RGB 格式\n",
    "            frames.append(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(f\"No frames could be read from the video at {video_path}.\")\n",
    "\n",
    "    # 转换为 Tensor 格式，形状为 (frames, height, width, channels)\n",
    "    video_tensor = torch.tensor(np.array(frames), dtype=torch.float32).permute(3, 0, 1, 2) / 255.0\n",
    "    return video_tensor.unsqueeze(0)  # 增加 batch 维度\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, device, video_tensor, epochs):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # 模拟标签\n",
    "    label = torch.tensor([1], device=device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        video_tensor = video_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(video_tensor)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    total_start_time = time.time()\n",
    "    video_path = \"/data/dengqi_code/Video_Test.mp4\"\n",
    "    fps_to_process = 2  # 每秒处理的帧数\n",
    "    frame_size = (64, 64)  # 降低分辨率以节省内存\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print('Loading video...')\n",
    "    load_video_start_time = time.time()\n",
    "    video_tensor = load_video(video_path, fps_to_process=fps_to_process, frame_size=frame_size)\n",
    "    load_video_end_time = time.time()\n",
    "\n",
    "    print('Training model...')\n",
    "    train_model_start_time = time.time()\n",
    "    input_shape = (1, *video_tensor.shape[1:])  \n",
    "    model = SimpleVideoCNN(input_shape)\n",
    "    train_model(model, device, video_tensor, epochs=5)\n",
    "    train_model_end_time = time.time()\n",
    "    total_end_time = time.time()\n",
    "\n",
    "    print(f\"Total time for loading video: {load_video_end_time - load_video_start_time:.2f} seconds\")\n",
    "    print(f\"Total time for training model: {train_model_end_time - train_model_start_time:.2f} seconds\")\n",
    "    print(f\"Total time for the whole process {total_end_time - total_start_time:.2f} seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割视频，单GPU（4090）多进程共同处理1小时视频\n",
    "\n",
    "num_segments = 16，total_time = 85.60\n",
    "\n",
    "num_segments = 8，total_time = 67.5\n",
    "\n",
    "num_segments = 4，total_time = 59.13\n",
    "\n",
    "num_segments = 2，total_time = 119.64\n",
    "\n",
    "num_segments = 1，total_time = 189.64\n",
    "\n",
    "需要注意，进程越多，CPU负载越大，当CPU、内存的负载超过达到100%，整体运行效率越低。当前算力下，16进程时，CPU负载已接近100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1023530 handling frames 0 to 43218 with fps_to_process=2 on cuda:0\n",
      "Process 1023533 handling frames 43218 to 86436 with fps_to_process=2 on cuda:0\n",
      "Process 1023530 - Epoch 1, Loss: 2.2617197036743164\n",
      "Process 1023530 - Epoch 2, Loss: 0.06742236763238907\n",
      "Process 1023530 - Epoch 3, Loss: 2.7894584491150454e-05\n",
      "Process 1023530 - Epoch 4, Loss: 2.777537883957848e-05\n",
      "Process 1023530 - Epoch 5, Loss: 2.7656173188006505e-05\n",
      "Process 1023530 - Time for loading video: 90.13 seconds\n",
      "Process 1023530 - Time for training model: 11.12 seconds\n",
      "Process 1023533 - Epoch 1, Loss: 2.262174606323242\n",
      "Process 1023533 - Epoch 2, Loss: 0.06669007241725922\n",
      "Process 1023533 - Epoch 3, Loss: 3.4689302992774174e-05\n",
      "Process 1023533 - Epoch 4, Loss: 3.421248038648628e-05\n",
      "Process 1023533 - Epoch 5, Loss: 3.397406908334233e-05\n",
      "Process 1023533 - Time for loading video: 106.65 seconds\n",
      "Process 1023533 - Time for training model: 9.51 seconds\n",
      "Total time for the whole process: 119.64 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "class SimpleVideoCNN(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(SimpleVideoCNN, self).__init__()\n",
    "        self.conv3d_1 = nn.Conv3d(3, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.pool_1 = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "        self.conv3d_2 = nn.Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.pool_2 = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(input_shape)\n",
    "            output = self.pool_2(self.conv3d_2(self.pool_1(self.conv3d_1(dummy_input))))\n",
    "            self.flatten_size = output.numel() // dummy_input.size(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv3d_1(x))\n",
    "        x = self.pool_1(x)\n",
    "        x = torch.relu(self.conv3d_2(x))\n",
    "        x = self.pool_2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_video(video_path, start_frame, end_frame, fps_to_process, frame_size=(64, 64)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(original_fps // fps_to_process) if fps_to_process and fps_to_process < original_fps else 1\n",
    "    frames = []\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        if current_frame >= end_frame:\n",
    "            break\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(f\"No frames could be read between {start_frame} and {end_frame}.\")\n",
    "\n",
    "    video_tensor = torch.tensor(np.array(frames), dtype=torch.float32).permute(3, 0, 1, 2) / 255.0\n",
    "    return video_tensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "def train_model(model, device, video_tensor, epochs):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    label = torch.tensor([1], device=device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        video_tensor = video_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(video_tensor)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Process {os.getpid()} - Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "def process_video_segment(video_path, start_frame, end_frame, fps_to_process, device, frame_size=(64, 64), epochs=5):\n",
    "    print(f\"Process {os.getpid()} handling frames {start_frame} to {end_frame} with fps_to_process={fps_to_process} on {device}\")\n",
    "\n",
    "    # Load video segment\n",
    "    load_video_start_time = time.time()\n",
    "    video_tensor = load_video(video_path, start_frame, end_frame, fps_to_process, frame_size)\n",
    "    load_video_end_time = time.time()\n",
    "\n",
    "    # Initialize and train model\n",
    "    input_shape = (1, *video_tensor.shape[1:])\n",
    "    model = SimpleVideoCNN(input_shape)\n",
    "    train_model_start_time = time.time()\n",
    "    train_model(model, device, video_tensor, epochs)\n",
    "    train_model_end_time = time.time()\n",
    "\n",
    "    # Output timing details\n",
    "    print(f\"Process {os.getpid()} - Time for loading video: {load_video_end_time - load_video_start_time:.2f} seconds\")\n",
    "    print(f\"Process {os.getpid()} - Time for training model: {train_model_end_time - train_model_start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    video_path = \"/data/dengqi_code/Video_Test.mp4\"\n",
    "    total_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    original_fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "    num_segments = 2  # Number of segments to split video into\n",
    "    segment_length = total_frames // num_segments\n",
    "    fps_to_process = 2  # Target frames per second for processing\n",
    "    frame_size = (64, 64)\n",
    "    epochs = 5\n",
    "\n",
    "    device = torch.device(\"cuda:0\")  # Use cuda:0 for all processes\n",
    "    processes = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_frame = i * segment_length\n",
    "        end_frame = total_frames if i == num_segments - 1 else (i + 1) * segment_length\n",
    "        p = multiprocessing.Process(target=process_video_segment,\n",
    "                                    args=(video_path, start_frame, end_frame, fps_to_process, device, frame_size, epochs))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    print(f\"Total time for the whole process: {total_end_time - total_start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割视频，多GPU（3070+4090）多进程共同处理1小时视频\n",
    "\n",
    "num_segments = 8，total_time = 32.65\n",
    "\n",
    "num_segments = 4，total_time = 45.27\n",
    "\n",
    "num_segments = 2，total_time = 72.45\n",
    "\n",
    "注：进程总数为16时，3070显存过小，无法单独运行8个进程。在总进程数为8时，CPU负载已接近100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1048222 handling frames 0 to 5402 with fps_to_process=2 on cuda:0\n",
      "Process 1048225 handling frames 5402 to 10804 with fps_to_process=2 on cuda:0\n",
      "Process 1048230 handling frames 10804 to 16206 with fps_to_process=2 on cuda:0\n",
      "Process 1048235 handling frames 16206 to 21608 with fps_to_process=2 on cuda:0\n",
      "Process 1048240 handling frames 21608 to 27010 with fps_to_process=2 on cuda:0\n",
      "Process 1048261 handling frames 27010 to 32412 with fps_to_process=2 on cuda:0\n",
      "Process 1048282 handling frames 32412 to 37814 with fps_to_process=2 on cuda:0\n",
      "Process 1048313 handling frames 37814 to 43216 with fps_to_process=2 on cuda:0\n",
      "Process 1048340 handling frames 43216 to 48618 with fps_to_process=2 on cuda:1\n",
      "Process 1048350 handling frames 48618 to 54020 with fps_to_process=2 on cuda:1\n",
      "Process 1048368 handling frames 54020 to 59422 with fps_to_process=2 on cuda:1\n",
      "Process 1048405 handling frames 59422 to 64824 with fps_to_process=2 on cuda:1\n",
      "Process 1048438 handling frames 64824 to 70226 with fps_to_process=2 on cuda:1\n",
      "Process 1048445 handling frames 70226 to 75628 with fps_to_process=2 on cuda:1\n",
      "Process 1048479 handling frames 75628 to 81030 with fps_to_process=2 on cuda:1\n",
      "Process 1048500 handling frames 81030 to 86436 with fps_to_process=2 on cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-11:\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-9:\n",
      "Process Process-10:\n",
      "Process Process-14:\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "Traceback (most recent call last):\n",
      "Process Process-12:\n",
      "Process Process-13:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "Process Process-15:\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 102, in process_video_segment\n",
      "    train_model(model, device, video_tensor, epochs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 83, in train_model\n",
      "    output = model(video_tensor)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_1048154/3020333015.py\", line 28, in forward\n",
      "    x = torch.relu(self.conv3d_1(x))\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1190, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 613, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "  File \"/data/miniconda3/envs/ATSC/lib/python3.9/site-packages/torch/nn/modules/conv.py\", line 608, in _conv_forward\n",
      "    return F.conv3d(\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n",
      "RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 1048261 - Epoch 1, Loss: 2.3601021766662598\n",
      "Process 1048261 - Epoch 2, Loss: 1.724611520767212\n",
      "Process 1048261 - Epoch 3, Loss: 0.07725840061903\n",
      "Process 1048261 - Epoch 4, Loss: 0.007226163987070322\n",
      "Process 1048261 - Epoch 5, Loss: 0.004976979922503233\n",
      "Process 1048261 - Time for loading video: 13.05 seconds\n",
      "Process 1048261 - Time for training model: 17.61 seconds\n",
      "Process 1048235 - Epoch 1, Loss: 2.3586387634277344\n",
      "Process 1048235 - Epoch 2, Loss: 1.7322229146957397\n",
      "Process 1048235 - Epoch 3, Loss: 0.08189123868942261\n",
      "Process 1048235 - Epoch 4, Loss: 0.006522556766867638\n",
      "Process 1048235 - Epoch 5, Loss: 0.00460789306089282\n",
      "Process 1048235 - Time for loading video: 13.86 seconds\n",
      "Process 1048235 - Time for training model: 17.88 seconds\n",
      "Process 1048225 - Epoch 1, Loss: 2.359348773956299\n",
      "Process 1048225 - Epoch 2, Loss: 1.724930763244629\n",
      "Process 1048225 - Epoch 3, Loss: 0.07835948467254639\n",
      "Process 1048225 - Epoch 4, Loss: 0.007175271399319172\n",
      "Process 1048225 - Epoch 5, Loss: 0.004953137598931789\n",
      "Process 1048225 - Time for loading video: 14.11 seconds\n",
      "Process 1048225 - Time for training model: 17.88 seconds\n",
      "Process 1048222 - Epoch 1, Loss: 2.3592724800109863\n",
      "Process 1048222 - Epoch 2, Loss: 1.7253986597061157\n",
      "Process 1048222 - Epoch 3, Loss: 0.0773615688085556\n",
      "Process 1048222 - Epoch 4, Loss: 0.007241667713969946\n",
      "Process 1048222 - Epoch 5, Loss: 0.00498646916821599\n",
      "Process 1048222 - Time for loading video: 14.54 seconds\n",
      "Process 1048222 - Time for training model: 17.87 seconds\n",
      "Process 1048282 - Epoch 1, Loss: 2.3574166297912598\n",
      "Process 1048282 - Epoch 2, Loss: 1.7644658088684082\n",
      "Process 1048282 - Epoch 3, Loss: 0.10047788172960281\n",
      "Process 1048282 - Epoch 4, Loss: 0.004958000965416431\n",
      "Process 1048282 - Epoch 5, Loss: 0.0037461596075445414\n",
      "Process 1048282 - Time for loading video: 15.46 seconds\n",
      "Process 1048282 - Time for training model: 17.93 seconds\n",
      "Process 1048313 - Epoch 1, Loss: 2.359132766723633\n",
      "Process 1048313 - Epoch 2, Loss: 1.7311882972717285\n",
      "Process 1048313 - Epoch 3, Loss: 0.08061236888170242\n",
      "Process 1048313 - Epoch 4, Loss: 0.006617062725126743\n",
      "Process 1048313 - Epoch 5, Loss: 0.004655356053262949\n",
      "Process 1048313 - Time for loading video: 15.86 seconds\n",
      "Process 1048313 - Time for training model: 17.63 seconds\n",
      "Process 1048240 - Epoch 1, Loss: 2.358842372894287\n",
      "Process 1048230 - Epoch 1, Loss: 2.358430862426758\n",
      "Process 1048240 - Epoch 2, Loss: 1.7220669984817505\n",
      "Process 1048230 - Epoch 2, Loss: 1.8414109945297241\n",
      "Process 1048240 - Epoch 3, Loss: 0.07508630305528641\n",
      "Process 1048230 - Epoch 3, Loss: 0.2561419904232025\n",
      "Process 1048240 - Epoch 4, Loss: 0.007422370370477438\n",
      "Process 1048230 - Epoch 4, Loss: 0.0005691815749742091\n",
      "Process 1048240 - Epoch 5, Loss: 0.005073529668152332\n",
      "Process 1048240 - Time for loading video: 16.12 seconds\n",
      "Process 1048240 - Time for training model: 17.87 seconds\n",
      "Process 1048230 - Epoch 5, Loss: 0.0005433275364339352\n",
      "Process 1048230 - Time for loading video: 16.04 seconds\n",
      "Process 1048230 - Time for training model: 17.89 seconds\n",
      "Total time for the whole process: 35.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "class SimpleVideoCNN(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(SimpleVideoCNN, self).__init__()\n",
    "        self.conv3d_1 = nn.Conv3d(3, 4, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.pool_1 = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "        self.conv3d_2 = nn.Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=1)\n",
    "        self.pool_2 = nn.MaxPool3d(kernel_size=(2, 2, 2))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(input_shape)\n",
    "            output = self.pool_2(self.conv3d_2(self.pool_1(self.conv3d_1(dummy_input))))\n",
    "            self.flatten_size = output.numel() // dummy_input.size(0)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv3d_1(x))\n",
    "        x = self.pool_1(x)\n",
    "        x = torch.relu(self.conv3d_2(x))\n",
    "        x = self.pool_2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def load_video(video_path, start_frame, end_frame, fps_to_process, frame_size=(64, 64)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    original_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_interval = int(original_fps // fps_to_process) if fps_to_process and fps_to_process < original_fps else 1\n",
    "    frames = []\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        if current_frame >= end_frame:\n",
    "            break\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % frame_interval == 0:\n",
    "            frame = cv2.resize(frame, frame_size)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        raise ValueError(f\"No frames could be read between {start_frame} and {end_frame}.\")\n",
    "\n",
    "    video_tensor = torch.tensor(np.array(frames), dtype=torch.float32).permute(3, 0, 1, 2) / 255.0\n",
    "    return video_tensor.unsqueeze(0)\n",
    "\n",
    "\n",
    "def train_model(model, device, video_tensor, epochs):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    label = torch.tensor([1], device=device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        video_tensor = video_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(video_tensor)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Process {os.getpid()} - Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "def process_video_segment(video_path, start_frame, end_frame, fps_to_process, device, frame_size=(64, 64), epochs=5):\n",
    "    print(f\"Process {os.getpid()} handling frames {start_frame} to {end_frame} with fps_to_process={fps_to_process} on {device}\")\n",
    "\n",
    "    # Load video segment\n",
    "    load_video_start_time = time.time()\n",
    "    video_tensor = load_video(video_path, start_frame, end_frame, fps_to_process, frame_size)\n",
    "    load_video_end_time = time.time()\n",
    "\n",
    "    # Initialize and train model\n",
    "    input_shape = (1, *video_tensor.shape[1:])\n",
    "    model = SimpleVideoCNN(input_shape)\n",
    "    train_model_start_time = time.time()\n",
    "    train_model(model, device, video_tensor, epochs)\n",
    "    train_model_end_time = time.time()\n",
    "\n",
    "    # Output timing details\n",
    "    print(f\"Process {os.getpid()} - Time for loading video: {load_video_end_time - load_video_start_time:.2f} seconds\")\n",
    "    print(f\"Process {os.getpid()} - Time for training model: {train_model_end_time - train_model_start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    video_path = \"/data/dengqi_code/Video_Test.mp4\"\n",
    "    total_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    original_fps = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "    num_segments = 16  # Number of segments to split video into\n",
    "    segment_length = total_frames // num_segments\n",
    "    fps_to_process = 2  # Target frames per second for processing\n",
    "    frame_size = (64, 64)\n",
    "    epochs = 5\n",
    "\n",
    "    # Assign devices to processes\n",
    "    devices = [torch.device(\"cuda:0\")] * (num_segments // 2) + [torch.device(\"cuda:1\")] * (num_segments // 2)\n",
    "    processes = []\n",
    "\n",
    "    # Launch processes\n",
    "    for i, device in enumerate(devices):\n",
    "        start_frame = i * segment_length\n",
    "        end_frame = total_frames if i == num_segments - 1 else (i + 1) * segment_length\n",
    "        p = multiprocessing.Process(target=process_video_segment,\n",
    "                                    args=(video_path, start_frame, end_frame, fps_to_process, device, frame_size, epochs))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    # Wait for all processes to finish\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "    total_end_time = time.time()\n",
    "    print(f\"Total time for the whole process: {total_end_time - total_start_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
